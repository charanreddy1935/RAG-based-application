{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b4a0da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b5a60b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing Chroma directory removed successfully.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('./chroma'):\n",
    "    try:\n",
    "        shutil.rmtree('./chroma')\n",
    "        print(\"Existing Chroma directory removed successfully.\")\n",
    "    except PermissionError as e:\n",
    "        print(f\"PermissionError: Unable to remove './chroma' directory: {e}\")\n",
    "        print(\"Ensure no processes are using the './chroma' directory and try running as administrator.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error removing Chroma directory: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab5873d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chara\\AppData\\Local\\Temp\\ipykernel_15260\\3886928256.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_llm = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "c:\\Users\\chara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "embedding_llm = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1672c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6126a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b3aab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "176dce19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks created: 2236\n"
     ]
    }
   ],
   "source": [
    "base = Path.cwd()  # Current working directory\n",
    "candidates = [\n",
    "    base / \"HDFC_Faq.txt\",\n",
    "    base.parent / \"HDFC_Faq.txt\",                  # One level up\n",
    "    base / \"HDFC_ChatBot-main\" / \"HDFC_Faq.txt\",   # Nested variant\n",
    "    Path(\"C:/Users/chara/Downloads/HDFC_ChatBot-main/HDFC_ChatBot-main/HDFC_Faq.txt\")  # Absolute path\n",
    "]\n",
    "\n",
    "faq_file = None\n",
    "for candidate in candidates:\n",
    "    if candidate.exists():\n",
    "        faq_file = candidate\n",
    "        break\n",
    "\n",
    "if faq_file is None:\n",
    "    raise FileNotFoundError(\"HDFC_Faq.txt not found in any of the specified locations\")\n",
    "\n",
    "# Read and process the FAQ file\n",
    "with open(faq_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read().strip()\n",
    "\n",
    "# Ensure valid JSON format\n",
    "if not raw_text.startswith(\"[\"):\n",
    "    raw_text = \"[\" + raw_text\n",
    "if not raw_text.endswith(\"]\"):\n",
    "    raw_text = raw_text.rstrip(\",\") + \"]\"\n",
    "\n",
    "# Parse JSON and create documents\n",
    "faq_data = json.loads(raw_text)\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=f\"Q: {item['question']}\\nA: {item['answer']}\",\n",
    "        metadata={\"source\": str(faq_file)}\n",
    "    )\n",
    "    for item in faq_data\n",
    "]\n",
    "print(f\"Number of chunks created: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9165ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(\n",
    "    documents,\n",
    "    embedding_llm,\n",
    "    persist_directory=\"./chroma\",\n",
    "    collection_name=\"hdfc_faqs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fef16f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chara\\AppData\\Local\\Temp\\ipykernel_15260\\123899826.py:1: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    }
   ],
   "source": [
    "db.persist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
